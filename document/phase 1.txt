Phase 1 : Configuration et collecte des donn√©es
Objectif
Configurer l‚Äôenvironnement pour utiliser IQFeed exclusivement comme source de donn√©es, collecter les donn√©es brutes (OHLC, DOM, options, news, cross-market, √©v√©nements macro), supprimer toute r√©f√©rence √† dxFeed, obs_t, et 320/81 features, et g√©n√©rer les fichiers de donn√©es initiaux (ex. : iqfeed_data.csv, macro_events.csv). Cette phase est prioritaire, car elle fournit les donn√©es n√©cessaires pour toutes les autres phases (ex. : features, entra√Ænement, trading).

Fichiers concern√©s
Fichiers principaux (5) :
src/data/data_provider.py
src/api/merge_data_sources.py
src/api/schedule_economic_calendar.py
config/credentials.yaml
config/market_config.yaml
Fichiers g√©n√©r√©s (4) :
data/iqfeed/iqfeed_data.csv
data/iqfeed/merged_data.csv
data/macro_events.csv
data/iqfeed/news.csv
Tests (3) :
tests/test_data_provider.py
tests/test_merge_data_sources.py
tests/test_schedule_economic_calendar.py
D√©pendances (2) :
src/model/utils/alert_manager.py
src/model/utils/config_manager.py
Registre des fichiers (Phase 1)
Fichier	Statut	Version	Date	Probl√®mes	Tests	Priorit√©	D√©pendances	Fichiers g√©n√©r√©s
src/data/data_provider.py	Existant	2.1.3	2025-05-13	obs_t, dxFeed	tests/test_data_provider.py	Tr√®s haute	config/credentials.yaml, alert_manager.py	iqfeed_data.csv, option_chain.csv, cross_market.csv, news.csv
src/api/merge_data_sources.py	Existant	2.1.3	2025-05-13	obs_t, dxFeed	tests/test_merge_data_sources.py	Tr√®s haute	data_provider.py, config_manager.py	merged_data.csv
src/api/schedule_economic_calendar.py	Existant	2.1.3	2025-05-13	obs_t, dxFeed	tests/test_schedule_economic_calendar.py	Haute	config/credentials.yaml, alert_manager.py	macro_events.csv
config/credentials.yaml	Existant	2.1.3	2025-05-13	Aucun	tests/test_credentials.py	Moyenne	Aucun	Aucun
config/market_config.yaml	Existant	2.1.3	2025-05-13	Aucun	tests/test_market_config.py	Moyenne	Aucun	Aucun
data/iqfeed/iqfeed_data.csv	√Ä g√©n√©rer	2.1.3	2025-05-13	Aucun	tests/test_data_provider.py	Basse	data_provider.py	Aucun
data/iqfeed/merged_data.csv	√Ä g√©n√©rer	2.1.3	2025-05-13	Aucun	tests/test_merge_data_sources.py	Basse	merge_data_sources.py	Aucun
data/macro_events.csv	√Ä g√©n√©rer	2.1.3	2025-05-13	Aucun	tests/test_schedule_economic_calendar.py	Basse	schedule_economic_calendar.py	Aucun
data/iqfeed/news.csv	√Ä g√©n√©rer	2.1.3	2025-05-13	Aucun	tests/test_data_provider.py	Basse	data_provider.py	Aucun
Sp√©cifications des fichiers
Module : src/data/data_provider.py
R√¥le :
Collecte les donn√©es brutes via IQFeed (OHLC, DOM, options, news, cross-market) et g√©n√®re iqfeed_data.csv, option_chain.csv, cross_market.csv, news.csv.
Statut :
Existant (√† mettre √† jour).
Fonctionnalit√©s existantes √† pr√©server :
Collecte des donn√©es IQFeed via IQFeedProvider.
Structure des fichiers g√©n√©r√©s (iqfeed_data.csv, option_chain.csv, etc.).
Modifications n√©cessaires :
Supprimer toute r√©f√©rence √† obs_t, dxFeed, 320/81 features.
Ajouter retries (max 3, d√©lai 2^attempt) pour les appels IQFeed.
Ajouter logs psutil dans data/logs/provider_performance.csv.
Ajouter alertes via alert_manager.py pour les erreurs critiques.
V√©rifier/cr√©er les fichiers g√©n√©r√©s avec les sch√©mas suivants :
Sch√©ma pour data/iqfeed/iqfeed_data.csv :
timestamp : datetime (ex. : 2025-05-13 14:00:00)
bid : float (ex. : 5100.25)
ask : float (ex. : 5100.50)
bid_size_level_2 : float (ex. : 100.0)
spy_close : float (ex. : 450.75)
vix_es_correlation : float (ex. : 0.85)
atr_14 : float (ex. : 15.5)
Sch√©ma pour data/iqfeed/option_chain.csv :
timestamp : datetime (ex. : 2025-05-13 14:00:00)
strike : float (ex. : 5100.0)
option_type : str (ex. : call)
open_interest : int (ex. : 500)
call_iv_atm : float (ex. : 0.25)
put_iv_atm : float (ex. : 0.27)
option_volume : int (ex. : 1000)
oi_concentration : float (ex. : 0.65)
option_skew : float (ex. : 0.05)
Sch√©ma pour data/iqfeed/cross_market.csv :
timestamp : datetime (ex. : 2025-05-13 14:00:00)
symbol : str (ex. : SPY)
close : float (ex. : 450.75)
vix_es_correlation : float (ex. : 0.85)
Sch√©ma pour data/iqfeed/news.csv :
timestamp : datetime (ex. : 2025-05-13 14:00:00)
headline : str (ex. : "FOMC annonce une hausse des taux")
source : str (ex. : Reuters)
Priorit√© :
Tr√®s haute (base pour toutes les phases).
D√©pendances :
config/credentials.yaml
config/market_config.yaml
src/model/utils/alert_manager.py
src/model/utils/config_manager.py
Fichiers g√©n√©r√©s :
data/iqfeed/iqfeed_data.csv
data/iqfeed/option_chain.csv
data/iqfeed/cross_market.csv
data/iqfeed/news.csv
Action :
Mettre √† jour data_provider.py avec :
python

Copier
import pandas as pd
import psutil
from src.model.utils.alert_manager import AlertManager
from src.model.utils.config_manager import config_manager
class IQFeedProvider:
    def fetch_ohlc(self, symbol):
        config = config_manager.get_config("market_config.yaml")
        start_time = time.time()
        try:
            data = self._fetch_iqfeed_data(symbol)
            data.to_csv("data/iqfeed/iqfeed_data.csv", encoding="utf-8", index=False)
            latency = time.time() - start_time
            self._log_performance("fetch_ohlc", latency, success=True)
            return data
        except Exception as e:
            self._log_performance("fetch_ohlc", time.time() - start_time, success=False, error=str(e))
            AlertManager().send_alert(f"Erreur fetch_ohlc: {str(e)}", priority=3)
            raise
    def _log_performance(self, operation, latency, success=True, error=None):
        log_entry = {
            "timestamp": datetime.now().strftime("%Y%m%d_%H%M%S"),
            "operation": operation,
            "latency": latency,
            "success": success,
            "error": error,
            "memory_usage_mb": psutil.Process().memory_info().rss / 1024 / 1024,
            "cpu_percent": psutil.cpu_percent()
        }
        pd.DataFrame([log_entry]).to_csv("data/logs/provider_performance.csv", mode="a", header=False, index=False)
V√©rifier/cr√©er les fichiers g√©n√©r√©s avec les sch√©mas ci-dessus.
Tests :
Fichier : tests/test_data_provider.py
Sc√©narios :
V√©rifier la cr√©ation de iqfeed_data.csv, option_chain.csv, cross_market.csv, news.csv.
V√©rifier les colonnes et l‚Äôabsence de NaN.
Tester les erreurs r√©seau IQFeed.
V√©rifier l‚Äôabsence de obs_t, dxFeed, 320/81 features.
Exemple :
python

Copier
def test_fetch_ohlc():
    from src.data.data_provider import IQFeedProvider
    provider = IQFeedProvider()
    data = provider.fetch_ohlc(symbol="ES")
    assert set(data.columns) == {"timestamp", "bid", "ask", "bid_size_level_2", "spy_close", "vix_es_correlation", "atr_14"}, "Colonnes incorrectes"
    assert not data.isna().any().any(), "NaN d√©tect√©s"
    assert os.path.exists("data/iqfeed/iqfeed_data.csv"), "Fichier non g√©n√©r√©"
Failles corrig√©es :
R√©sidus obs_t, dxFeed (supprim√©s).
Incoh√©rences features (align√© sur 350/150 SHAP).
Tests g√©n√©riques (tests sp√©cifiques).
Manque de sch√©ma pour les fichiers g√©n√©r√©s (sch√©mas d√©taill√©s).
Module : src/api/merge_data_sources.py
R√¥le :
Fusionne les donn√©es IQFeed (OHLC, options, news, cross-market) avec les √©v√©nements macro pour g√©n√©rer merged_data.csv.
Statut :
Existant (√† mettre √† jour).
Fonctionnalit√©s existantes √† pr√©server :
Fusion des donn√©es brutes.
Structure de merged_data.csv.
Modifications n√©cessaires :
Supprimer toute r√©f√©rence √† obs_t, dxFeed, 320/81 features.
Ajouter retries (max 3, d√©lai 2^attempt) pour les op√©rations de fusion.
Ajouter logs psutil dans data/logs/merge_data_sources_performance.csv.
Ajouter alertes via alert_manager.py.
V√©rifier/cr√©er merged_data.csv avec le sch√©ma suivant :
Sch√©ma pour data/iqfeed/merged_data.csv :
timestamp : datetime (ex. : 2025-05-13 14:00:00)
close : float (ex. : 5100.75)
news_impact_score : float (ex. : 0.65)
call_iv_atm : float (ex. : 0.25)
option_skew : float (ex. : 0.05)
Priorit√© :
Tr√®s haute (n√©cessaire pour la g√©n√©ration des features).
D√©pendances :
src/data/data_provider.py
src/model/utils/config_manager.py
src/model/utils/alert_manager.py
Fichiers g√©n√©r√©s :
data/iqfeed/merged_data.csv
Action :
Mettre √† jour merge_data_sources.py avec :
python

Copier
import pandas as pd
import psutil
from src.model.utils.alert_manager import AlertManager
def merge_data_sources():
    start_time = time.time()
    try:
        ohlc = pd.read_csv("data/iqfeed/iqfeed_data.csv")
        news = pd.read_csv("data/iqfeed/news.csv")
        merged = ohlc.merge(news, on="timestamp", how="left")
        merged.to_csv("data/iqfeed/merged_data.csv", encoding="utf-8", index=False)
        latency = time.time() - start_time
        log_entry = {
            "timestamp": datetime.now().strftime("%Y%m%d_%H%M%S"),
            "operation": "merge_data",
            "latency": latency,
            "success": True,
            "memory_usage_mb": psutil.Process().memory_info().rss / 1024 / 1024,
            "cpu_percent": psutil.cpu_percent()
        }
        pd.DataFrame([log_entry]).to_csv("data/logs/merge_data_sources_performance.csv", mode="a", header=False, index=False)
    except Exception as e:
        AlertManager().send_alert(f"Erreur fusion: {str(e)}", priority=3)
        raise
V√©rifier/cr√©er merged_data.csv avec le sch√©ma ci-dessus.
Tests :
Fichier : tests/test_merge_data_sources.py
Sc√©narios :
V√©rifier la cr√©ation de merged_data.csv.
V√©rifier les colonnes et l‚Äôabsence de NaN.
Tester les erreurs de fusion (ex. : fichiers manquants).
V√©rifier l‚Äôabsence de obs_t, dxFeed, 320/81 features.
Exemple :
python

Copier
def test_merge_data_sources():
    from src.api.merge_data_sources import merge_data_sources
    merge_data_sources()
    df = pd.read_csv("data/iqfeed/merged_data.csv")
    assert set(df.columns) == {"timestamp", "close", "news_impact_score", "call_iv_atm", "option_skew"}, "Colonnes incorrectes"
    assert not df.isna().any().any(), "NaN d√©tect√©s"
Failles corrig√©es :
R√©sidus obs_t, dxFeed (supprim√©s).
Incoh√©rences features (align√© sur 350/150 SHAP).
Tests g√©n√©riques (tests sp√©cifiques).
Manque de sch√©ma (sch√©ma d√©taill√©).
Module : src/api/schedule_economic_calendar.py
R√¥le :
Collecte les √©v√©nements macro-√©conomiques (ex. : FOMC, NFP) via l‚ÄôAPI Investing.com et g√©n√®re macro_events.csv.
Statut :
Existant (√† mettre √† jour).
Fonctionnalit√©s existantes √† pr√©server :
Collecte des √©v√©nements macro.
Structure de macro_events.csv (colonnes : start_time, type, impact).
Modifications n√©cessaires :
Supprimer toute r√©f√©rence √† obs_t, dxFeed, 320/81 features.
Int√©grer m√©thode 7 : Ajouter cluster_id via K-means sur vix_es_correlation.
Ajouter retries (max 3, d√©lai 2^attempt) pour les appels API.
Ajouter logs psutil dans data/logs/schedule_economic_calendar_performance.csv.
Ajouter alertes via alert_manager.py.
V√©rifier/cr√©er macro_events.csv avec le sch√©ma suivant :
Sch√©ma pour data/macro_events.csv :
start_time : datetime (ex. : 2025-05-13 14:00:00)
type : str (ex. : FOMC)
impact : float (ex. : 0.8)
cluster_id : int (ex. : 3)
Priorit√© :
Haute (n√©cessaire pour context_aware_filter.py).
D√©pendances :
config/credentials.yaml
config/market_config.yaml
src/model/utils/alert_manager.py
src/model/utils/config_manager.py
Fichiers g√©n√©r√©s :
data/macro_events.csv
Action :
Mettre √† jour schedule_economic_calendar.py avec :
python

Copier
import pandas as pd
import psutil
from sklearn.cluster import KMeans
from src.model.utils.alert_manager import AlertManager
def fetch_macro_events():
    start_time = time.time()
    try:
        data = api_investing_com.fetch_events()
        data["cluster_id"] = KMeans(n_clusters=10).fit_predict(data[["vix_es_correlation"]])
        data.to_csv("data/macro_events.csv", encoding="utf-8", index=False)
        latency = time.time() - start_time
        log_entry = {
            "timestamp": datetime.now().strftime("%Y%m%d_%H%M%S"),
            "operation": "fetch_macro_events",
            "latency": latency,
            "success": True,
            "memory_usage_mb": psutil.Process().memory_info().rss / 1024 / 1024,
            "cpu_percent": psutil.cpu_percent()
        }
        pd.DataFrame([log_entry]).to_csv("data/logs/schedule_economic_calendar_performance.csv", mode="a", header=False, index=False)
    except Exception as e:
        AlertManager().send_alert(f"Erreur fetch_macro_events: {str(e)}", priority=3)
        raise
V√©rifier/cr√©er macro_events.csv avec le sch√©ma ci-dessus.
Tests :
Fichier : tests/test_schedule_economic_calendar.py
Sc√©narios :
V√©rifier la cr√©ation de macro_events.csv.
V√©rifier les colonnes start_time, type, impact, cluster_id.
V√©rifier l‚Äôabsence de NaN.
Tester les erreurs API (ex. : r√©seau).
V√©rifier l‚Äôabsence de obs_t, dxFeed, 320/81 features.
Exemple :
python

Copier
def test_fetch_macro_events():
    from src.api.schedule_economic_calendar import fetch_macro_events
    fetch_macro_events()
    df = pd.read_csv("data/macro_events.csv")
    assert set(df.columns) == {"start_time", "type", "impact", "cluster_id"}, "Colonnes incorrectes"
    assert not df.isna().any().any(), "NaN d√©tect√©s"
Failles corrig√©es :
R√©sidus obs_t, dxFeed (supprim√©s).
Incoh√©rences features (align√© sur 350/150 SHAP).
Tests g√©n√©riques (tests sp√©cifiques).
Manque de sch√©ma (sch√©ma d√©taill√©).
Module : config/credentials.yaml
R√¥le :
Contient les identifiants s√©curis√©s pour les APIs (IQFeed, Investing.com, NewsAPI).
Statut :
Existant (√† v√©rifier).
Fonctionnalit√©s existantes √† pr√©server :
Structure des identifiants (ex. : iqfeed_api_key, investing_com_api_key).
Modifications n√©cessaires :
V√©rifier l‚Äôabsence de r√©f√©rences √† dxFeed.
Mettre √† jour la documentation (en-t√™te) pour refl√©ter la date 2025-05-13 et la version 2.1.3.
V√©rifier la compatibilit√© avec data_provider.py et schedule_economic_calendar.py.
Priorit√© :
Moyenne (n√©cessaire pour la collecte des donn√©es).
D√©pendances :
Aucun.
Fichiers g√©n√©r√©s :
Aucun.
Action :
V√©rifier/mettre √† jour credentials.yaml avec :
yaml

Copier
# config/credentials.yaml
# Identifiants s√©curis√©s pour les APIs
# Version : 2.1.3
# Date : 2025-05-13
iqfeed_api_key: yyy
investing_com_api_key: zzz
news_api_key: xxx
V√©rifier l‚Äôabsence de dxfeed_api_key ou autres r√©f√©rences obsol√®tes.
Tests :
Fichier : tests/test_credentials.py
Sc√©narios :
V√©rifier la pr√©sence des cl√©s iqfeed_api_key, investing_com_api_key, news_api_key.
V√©rifier l‚Äôabsence de dxfeed_api_key.
Tester la lecture par config_manager.py.
Exemple :
python

Copier
def test_credentials():
    from src.model.utils.config_manager import config_manager
    config = config_manager.get_config("credentials.yaml")
    assert "iqfeed_api_key" in config, "Cl√© IQFeed manquante"
    assert "dxfeed_api_key" not in config, "R√©f√©rence dxFeed d√©tect√©e"
Failles corrig√©es :
R√©f√©rences dxFeed (supprim√©es).
Documentation obsol√®te (mise √† jour).
Module : config/market_config.yaml
R√¥le :
Configure le march√© (ex. : ES) et les param√®tres IQFeed (ex. : h√¥te, symboles).
Statut :
Existant (√† v√©rifier).
Fonctionnalit√©s existantes √† pr√©server :
Param√®tres du march√© (ex. : symbol, max_drawdown, paper_trading_enabled).
Modifications n√©cessaires :
V√©rifier l‚Äôabsence de r√©f√©rences √† dxFeed.
Mettre √† jour la documentation (en-t√™te) pour refl√©ter la date 2025-05-13 et la version 2.1.3.
V√©rifier la compatibilit√© avec data_provider.py.
Priorit√© :
Moyenne (n√©cessaire pour la collecte des donn√©es).
D√©pendances :
Aucun.
Fichiers g√©n√©r√©s :
Aucun.
Action :
V√©rifier/mettre √† jour market_config.yaml avec :
yaml

Copier
# config/market_config.yaml
# Configuration du march√© ES et IQFeed
# Version : 2.1.3
# Date : 2025-05-13
symbol: ES
max_drawdown: 0.05
paper_trading_enabled: true
iqfeed_host: localhost
V√©rifier l‚Äôabsence de dxfeed_host ou autres r√©f√©rences obsol√®tes.
Tests :
Fichier : tests/test_market_config.py
Sc√©narios :
V√©rifier la pr√©sence des cl√©s symbol, max_drawdown, paper_trading_enabled, iqfeed_host.
V√©rifier l‚Äôabsence de dxfeed_host.
Tester la lecture par config_manager.py.
Exemple :
python

Copier
def test_market_config():
    from src.model.utils.config_manager import config_manager
    config = config_manager.get_config("market_config.yaml")
    assert "iqfeed_host" in config, "Cl√© IQFeed manquante"
    assert "dxfeed_host" not in config, "R√©f√©rence dxFeed d√©tect√©e"
Failles corrig√©es :
R√©f√©rences dxFeed (supprim√©es).
Documentation obsol√®te (mise √† jour).
Clarifications finales
Avant de passer √† la Phase 2, je dois confirmer quelques points pour m‚Äôassurer que la Phase 1 est compl√®te et conforme √† vos attentes :

Fichiers de la Phase 1 :
Les fichiers propos√©s (data_provider.py, merge_data_sources.py, schedule_economic_calendar.py, credentials.yaml, market_config.yaml) sont-ils corrects pour la Phase 1, ou voulez-vous ajouter/retirer des fichiers (ex. : inclure news_scraper.py ou un des 7 fournis) ?
Si vous avez une liste pr√©cise des fichiers les plus importants de structure.txt, partagez-la pour ajuster les priorit√©s.
Tests unitaires :
Les exemples de tests complets pour data_provider.py, merge_data_sources.py, et schedule_economic_calendar.py sont-ils adapt√©s, ou voulez-vous des sc√©narios limites sp√©cifiques (ex. : erreurs r√©seau, fichiers CSV mal format√©s) ?
Sch√©ma des fichiers g√©n√©r√©s :
Les sch√©mas d√©taill√©s propos√©s (ex. : pour iqfeed_data.csv, macro_events.csv) sont-ils au bon niveau de d√©tail, ou voulez-vous plus/moins d‚Äôinformations (ex. : contraintes suppl√©mentaires, descriptions des colonnes) ?
Registre des fichiers :
Le registre partiel pour la Phase 1 est-il clair ? Voulez-vous que j‚Äôinclue le registre complet des ~70 fichiers dans l‚Äôintroduction du guide, ou seulement les registres par phase ?
Validation de la Phase 1 :
Si la Phase 1 vous convient, dites "ok", et je passerai √† la Phase 2 (g√©n√©ration et filtrage des features, ex. : feature_pipeline.py, shap_weighting.py).
Si vous voulez des ajustements (ex. : ajouter un fichier, modifier un sch√©ma), pr√©cisez-les avant validation.
Conclusion
Le d√©compte confirme environ 142 fichiers dans structure.txt, mais les ~70 fichiers principaux (scripts Python, configurations, fichiers g√©n√©r√©s cl√©s) seront le focus du guide ultime. Votre validation des 10 phases, des tests complets pour prioritaires/stubs pour autres, et d‚Äôune version compl√®te pour validate_prompt_compliance.py permet de structurer un guide clair et robuste. La Phase 1 ci-dessus est con√ßue pour √™tre lisible, d√©taill√©e, et conforme √† vos exemples, avec des sch√©mas d√©taill√©s et des tests complets pour les fichiers critiques.

Actions imm√©diates demand√©es :

Validez la Phase 1 en disant "ok" si elle convient, ou pr√©cisez les ajustements n√©cessaires (ex. : fichiers √† ajouter/retirer, d√©tails des sch√©mas).
Confirmez les fichiers prioritaires pour la Phase 1 (proposition ci-dessus ou liste sp√©cifique).
Pr√©cisez si vous voulez le registre complet des ~70 fichiers dans l‚Äôintroduction du guide, ou seulement par phase.
Si possible, partagez une liste des fichiers les plus importants ou probl√©matiques parmi les ~70 cod√©s pour orienter les prochaines phases.
Une fois votre "ok" re√ßu, je r√©digerai la Phase 2. On avance pas √† pas pour boucler ce projet sans reprises ! üöÄ